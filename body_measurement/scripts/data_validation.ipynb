{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 22:30:01.606331: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-14 22:30:01.643814: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-14 22:30:01.644725: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-14 22:30:02.225352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from train import BodyPartsMeasurementTrainer\n",
    "from body_parts_measurement_data_generator import BodyPartsMeasurementDataGenerator\n",
    "import tensorflow as tf\n",
    "from evaluator import Evaluator\n",
    "from model.model import get_model\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = \"D:\\\\data\\\\body_parts_measurement\"\n",
    "path_dataset = \"/home/juhwan/Documents/capstone/body_part_measurement/dataset/korean_body/validation\"\n",
    "data_type = \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # model\n",
    "    'input_shape': [256,256,3],     # 훈련 이미지 크기\n",
    "    'batch_size': 1,                # 배치 사이즈\n",
    "    'path_pretrained': None,        # pretrained 모델 경로\n",
    "    'type_backbone': \"blazepose\",   # backbone type (blazepose, mobilenet_v3)\n",
    "    \n",
    "    # loss\n",
    "    'type_loss_fn': 'wing',         # 손실 함수 설정 (wing, mae)\n",
    "    \n",
    "    # data\n",
    "    'seg_shape': [64,64],           # segmentation 크기 *미사용\n",
    "    'path_classes': \"../seg_classes.txt\",   # segmentation class 정보 *미사용\n",
    "    'shuffle': True,                # 데이터 섞기\n",
    "    'is_normalized': False,         # normalize 데이터\n",
    "    'is_with_seg': False,           # segmentation 사용 여부 *미사용\n",
    "    #'path_dataset': \"D:\\\\data\\\\body_parts_measurement\", # 데이터 경로\n",
    "    'path_dataset': path_dataset, # 데이터 경로\n",
    "    ## attention type              \n",
    "    'type_attention': \"regression\", # attention 종류 (regression, categorical, none)\n",
    "    'num_category_bmi': 10,         # categorical 시의 bmi category 갯수 변수\n",
    "    'num_category_height': 10,      # categorical 시의 height category 갯수 변수\n",
    "\n",
    "    # train\n",
    "    'epochs': 30,                   # 훈련 epoch 수\n",
    "    'eval_term': 1                  # 평가 빈도\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config)\n",
    "# model.load_weights('blazepose_attention_31features_731train_mf/blazepose_attention_0_2.994556342230903.h5')\n",
    "#model.load_weights('blazepose_attention_31features_1002train_mf/blazepose_attention_0_3.2034787193590604.h5')\n",
    "model.load_weights('blazepose_attention_0_3.2034787193590604.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_user_dirs ['F001', 'F002', 'F003', 'F004', 'M001', 'M002', 'M003', 'M004']\n",
      "body_parts_measurement F001 36 ['161.4', '136.1', '80.1', '119.8', '94.2', '73.2', '41.6', '55.5', '35.2', '90.6', '80.5', '83.4', '98,6', '58.4', '38', '38', '21.3', '25', '29.3', '24', '16.7', '30.1', '52.1', '35.4', '21.2', '10.4', '22.9', '9.9', '12.9', '16', '9.2', '7.8', '62.9', '32.8', 'F', '37']\n",
      "body_parts_measurement F002 36 ['168.1', '140.4', '84.7', '123.3', '107', '77.3', '45.2', '54.7', '31.8', '88.5', '74.4', '81.5', '92', '51.3', '36', '35.5', '20.1', '24.2', '26.5', '22.7', '13.6', '30.8', '54.6', '35.4', '22.1', '10.8', '24.5', '9.3', '13', '17', '9.2', '7', '56.1', '31.5', 'F', '26']\n",
      "body_parts_measurement F003 36 ['163.4', '138.2', '81.9', '120.6', '97.1', '74.8', '42.3', '52', '30.5', '84.5', '76.5', '79.6', '88.2', '52.8', '32.9', '34.4', '18.9', '23.2', '26.3', '21', '14.2', '30.6', '52.5', '35.4', '19.2', '9.7', '22.4', '9.2', '11.2', '16.9', '9.7', '7.6', '53.2', '25.2', 'F', '39']\n",
      "body_parts_measurement F004 36 ['164.1', '137.8', '83.2', '123.3', '100.1', '75.4', '42.4', '56.5', '30', '80.5', '64.1', '67.2', '87.8', '50.3', '34.6', '32.8', '20.1', '23.7', '24.8', '21.9', '14', '32.6', '57', '33.5', '21.2', '10.8', '23.3', '9.3', '13.8', '17', '10.1', '7.6', '49.4', '21.8', 'F', '30']\n",
      "body_parts_measurement M001 36 ['177.2', '148.4', '83.6', '131.6', '104.3', '77.5', '46.6', '57.6', '36.7', '90.6', '85.1', '84.8', '98.2', '58.8', '39.1', '37.1', '21.3', '25.4', '31.9', '25.8', '16.6', '32.2', '58.9', '42', '21.7', '11.1', '24.8', '11.1', '13.4', '17.8', '10.1', '8.6', '73.4', '20.9', 'M', '38']\n",
      "body_parts_measurement M002 36 ['175.4', '147.1', '85', '128.5', '104.6', '75.4', '47.5', '59', '39.9', '94.9', '93.6', '95.3', '96.7', '59.3', '38.9', '37.6', '22.6', '27.6', '32.1', '26.6', '17.8', '32.4', '56.4', '40.9', '24.1', '12.7', '26.4', '10.2', '14.1', '19.4', '11.1', '8.6', '79.3', '24.3', 'M', '51']\n",
      "body_parts_measurement M003 36 ['175.6', '146.8', '82.6', '129.2', '102.6', '74.6', '44.4', '59.6', '37.6', '97.4', '82.9', '87.5', '99.4', '62.3', '36.9', '37.3', '23.1', '24.3', '34.2', '27', '16.1', '30.2', '52.3', '42.7', '21.8', '10.3', '23.3', '9.5', '15', '16.4', '9.7', '8.2', '76.1', '24.2', 'M', '26']\n",
      "body_parts_measurement M004 36 ['176.9', '145.9', '84.7', '128.2', '107.2', '78.3', '42.5', '59.5', '38.2', '93.6', '81.5', '86.3', '102.2', '62.0', '37.3', '38.6', '23.8', '26.8', '33.4', '26.8', '16.8', '31.6', '57.3', '41.6', '23.9', '11.1', '26.6', '10.4', '15.0', '18.6', '11.2', '8.3', '77.6', '26.6', 'M', '21']\n"
     ]
    }
   ],
   "source": [
    "list_user_dirs = os.listdir(path_dataset + os.path.sep + data_type)\n",
    "list_user_dirs.sort()\n",
    "print(\"list_user_dirs\",list_user_dirs)\n",
    "list_data = []\n",
    "min_body_parts_measurement = np.full(37, 10000, dtype=np.float32)\n",
    "max_body_parts_measurement = np.zeros(37, dtype=np.float32)\n",
    "for user_dir in list_user_dirs :\n",
    "    path_full_user_dir = path_dataset + os.path.sep + data_type + os.path.sep + user_dir\n",
    "    path_user_csv = path_full_user_dir + os.path.sep + \"csv\" + os.path.sep + user_dir + \".csv\"\n",
    "    # df = pd.read_csv(path_user_csv, encoding = \"ISO-8859-1\")\n",
    "    df = pd.read_csv(path_user_csv, encoding = \"ISO-8859-1\")\n",
    "    body_parts_measurement = list(df.iloc[[1]].values[0][3:-1])\n",
    "    # # change gender to digit\n",
    "    # if body_parts_measurement[-2] == \"F\" : \n",
    "    #     body_parts_measurement[-2] = \"1\"\n",
    "    # elif body_parts_measurement[-2] == \"M\" :\n",
    "    #     body_parts_measurement[-2] = \"0\"\n",
    "    # else :\n",
    "    #     print(\"wrong in \",user_dir)\n",
    "    # # get bmi\n",
    "    # height = float(body_parts_measurement[0])\n",
    "    # weight = float(body_parts_measurement[32])\n",
    "    # attention_features = np.expand_dims(np.array([height, weight]),axis=0)\n",
    "    # bmi = weight / (height/100. * height/100.)\n",
    "    # body_parts_measurement.append(bmi)\n",
    "    print(\"body_parts_measurement\",user_dir,len(body_parts_measurement),list(body_parts_measurement))\n",
    "    # body_parts_measurement = body_parts_measurement[1:32]            \n",
    "    # body_parts_measurement = np.array(body_parts_measurement, dtype=np.float32)\n",
    "    # ##### get list of images\n",
    "    # path_user_image_dir = path_full_user_dir + os.path.sep + \"image\"\n",
    "    # # get only images for attention posture\n",
    "    # list_path_images = glob.glob(path_user_image_dir + os.path.sep + \"*.jpg\")\n",
    "    # for path_image in list_path_images :\n",
    "    #     image = cv2.imread(path_image)\n",
    "    #     image = cv2.resize(image, (256, 256))\n",
    "    #     input_image = np.expand_dims(image, axis=0)\n",
    "    #     pd_parts_measurements = model.predict([input_image, attention_features])\n",
    "        # batch_diff_parts_measurements = abs(batch_body_parts_measurement - pd_parts_measurements)\n",
    "        # batch_diff_percentage_parts_measurements = abs(batch_diff_parts_measurements / batch_body_parts_measurement)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
